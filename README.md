# JoÃ£o Alexandre â€“ Perfil Profissional

Sou engenheiro e cientista de dados, com mais de 10 anos de experiÃªncia em lideranÃ§a de projetos, gestÃ£o de processos, modelagem de dados e integraÃ§Ã£o de sistemas.

Atualmente participo do programa **AWS Cloud Data Engineering Scholarship**, promovido pela Compass UOL, e do curso de **PÃ³s-graduaÃ§Ã£o em Engenharia e CiÃªncia de Dados** pela UNIESP/PB. Estou aprofundando conhecimentos em **ETL**, bancos de dados, **Python**, visualizaÃ§Ã£o de dados e serviÃ§os em nuvem (AWS).
>
## ðŸŽ“ FormaÃ§Ã£o AcadÃªmica
- PÃ³s-graduaÃ§Ã£o em Engenharia e CiÃªncia de Dados (em andamento) â€“ UNIESP
- PÃ³s-graduaÃ§Ã£o em Engenharia de Dados
- PÃ³s-graduaÃ§Ã£o em Controladoria
- PÃ³s-graduaÃ§Ã£o em AnÃ¡lise de Sistemas
- PÃ³s-graduaÃ§Ã£o em GestÃ£o Financeira

---

## ðŸ›  Habilidades TÃ©cnicas
- **SQL** (SQLite, PostgreSQL, SQL Server)
- **Python** (Pandas, NumPy, Matplotlib)
- **Power BI**
- **Git** e **GitHub**
- **Modelagem de Dados**
- **IntegraÃ§Ã£o de Sistemas**
- Fundamentos de **AWS** (S3, EC2, RDS â€“ em aprendizado)

---

## ðŸ“‚ Projetos e EvidÃªncias
Este repositÃ³rio contÃ©m a estrutura completa dos sprints realizados no programa AWS Cloud Data Engineering, com todos os exercÃ­cios, desafios e apresentaÃ§Ãµes organizados por pasta:

```
engenharia-dados/
â”œâ”€â”€ imagens/                  # Recursos visuais
â”œâ”€â”€ sprint-1/                 # ExercÃ­cios e desafio da Sprint 1
â”œâ”€â”€ sprint-2/                 # ExercÃ­cios e desafio da Sprint 2
â””â”€â”€ README.md                 # (Este arquivo â€“ perfil profissional)
```

Cada sprint possui um `README.md` com descriÃ§Ã£o detalhada da estrutura, evidÃªncias dos exercÃ­cios (`.png`), scripts em Python (`.py`) e arquivos de apoio (`.csv`, `.txt`).

---

## ðŸ“ LocalizaÃ§Ã£o
ðŸ“Œ JoÃ£o Pessoa â€“ PB, Brasil

---

## ðŸš€ Objetivo Profissional
Transformar dados em soluÃ§Ãµes inteligentes para tomada de decisÃ£o, combinando experiÃªncia em processos com conhecimento tÃ©cnico em ciÃªncia de dados e nuvem. Estou em aprendizado constante e pronto para novos desafios.

---

# ðŸ“Š Projeto: Clustering â€” Student Performance (K-Means & HierÃ¡rquico)

## 1. Sobre
ImplementaÃ§Ã£o de **clustering** (aprendizado nÃ£o supervisionado) usando o dataset **Student Performance** (UCI/Kaggle).  
O objetivo Ã© segmentar estudantes com base em atributos acadÃªmicos e demogrÃ¡ficos, utilizando **K-Means** e **Clustering HierÃ¡rquico (Ward)**.

---

## 2. Estrutura
```
.
â”œâ”€â”€ clustering_student_performance.ipynb   # Notebook completo e parametrizado
â”œâ”€â”€ clustering_student_performance_cli.py  # Script Python com interface de linha de comando
â”œâ”€â”€ outputs_clustering_student/            # Resultados gerados (CSV + PNG)
â”‚   â”œâ”€â”€ dataset_com_clusters_kmeans.csv
â”‚   â”œâ”€â”€ dataset_com_clusters_hier.csv
â”‚   â”œâ”€â”€ perfil_clusters_kmeans.csv
â”‚   â”œâ”€â”€ perfil_clusters_hier.csv
â”‚   â”œâ”€â”€ elbow_wcss.png
â”‚   â”œâ”€â”€ silhouette_k.png
â”‚   â”œâ”€â”€ dendrograma_ward.png
â”‚   â”œâ”€â”€ pca_kmeans.png
â”‚   â””â”€â”€ pca_hierarquico.png
```

---

## 3. Como usar

### 3.1 Notebook
1. Coloque seu dataset (`student-mat.csv` ou `student-por.csv`) na mesma pasta do notebook **ou** altere o caminho na primeira cÃ©lula:
```python
DATA_PATH = r'student-mat.csv'
```
2. Execute cÃ©lula a cÃ©lula no Jupyter.
3. Os resultados serÃ£o gravados em `outputs_clustering_student/`.

### 3.2 Script CLI
```bash
# Dataset MatemÃ¡tica (separador ;)
python clustering_student_performance_cli.py --data-path "C:\caminho\student-mat.csv"

# Dataset PortuguÃªs
python clustering_student_performance_cli.py --data-path "C:\caminho\student-por.csv" --save-dir outputs_por

# CSV com outro separador
python clustering_student_performance_cli.py --data-path "C:\...\meuarquivo.csv" --sep ","
```

**ParÃ¢metros principais:**
- `--data-path`: caminho do CSV local (**obrigatÃ³rio**)
- `--sep`: separador do CSV (default: `;`)
- `--save-dir`: pasta de saÃ­da (default: `outputs_clustering_student_cli`)
- `--max-k`: maior k testado no K-Means (default: `8`)
- `--sample-dendro`: nÂº mÃ¡ximo de amostras no dendrograma (default: `400`)

---

## 4. Resultados
- **`dataset_com_clusters_kmeans.csv`**: dataset com ID de cluster K-Means
- **`dataset_com_clusters_hier.csv`**: dataset com ID de cluster hierÃ¡rquico
- **`perfil_clusters_*.csv`**: estatÃ­sticas por cluster (`G1`, `G2`, `absences`, `failures`, `studytime`)
- **GrÃ¡ficos**:
  - `elbow_wcss.png` â€” curva Elbow para WCSS
  - `silhouette_k.png` â€” Silhouette mÃ©dio por k
  - `dendrograma_ward.png` â€” dendrograma hierÃ¡rquico
  - `pca_kmeans.png` â€” projeÃ§Ã£o PCA colorida por cluster K-Means
  - `pca_hierarquico.png` â€” projeÃ§Ã£o PCA colorida por cluster hierÃ¡rquico

---

## 5. ObservaÃ§Ãµes
- PrÃ©-processamento inclui **one-hot encoding** para variÃ¡veis categÃ³ricas e **normalizaÃ§Ã£o z-score**.
- Melhor nÃºmero de clusters (k) Ã© escolhido pelo maior **Silhouette mÃ©dio**.
- O dendrograma Ã© amostrado para manter a legibilidade.
>>>>>>> 6d03213 (docs: unifica perfil profissional e README do projeto de clustering)
